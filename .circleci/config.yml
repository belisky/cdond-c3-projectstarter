version: 2.1
orbs:
  node: circleci/node@5.0.2
  slack: circleci/slack@4.10.1
  aws-cli: circleci/aws-cli@1.3.0

# Define a job to be invoked later in a workflow.
# See: https://circleci.com/docs/2.0/configuration-reference/#jobs
commands:
  destroy-environment:
    description: Destroy back-end and front-end cloudformation stacks given a workflow ID.
    parameters:
      workflow_id:
        type: string
    steps:
      - run:
          name: Destroy environments
          when: on_fail
          command: |            
            aws s3 rm --recursive s3://udapeople-by-nobel-1           
            aws cloudformation delete-stack --stack-name "udapeople-backend-${CIRCLE_WORKFLOW_ID:0:7}"
            aws cloudformation delete-stack --stack-name "frontend-${CIRCLE_WORKFLOW_ID:0:7}"

  revert-migrations:
    description: Revert the last migration if successfully run in the current workflow.
   
    steps:
      # Trigger rollback jobs if the smoke tests or any following jobs fail.
      # Revert the last migration (IF a new migration was applied) on the database to that it goes back to the way it was before. You can use that value you saved in MemStash.io to know if you should revert any migrations.
      - run:
          name: Revert migrations
          when: on_fail
          command: |
            # Curl command here to see if there was a successful migration associated with the workflow id, store result in SUCCESS variable
            export SUCCESS=$(curl -k https://kvdb.io/Dvw7Sb8Hz69YirzDipb8Ld/migration_${CIRCLE_WORKFLOW_ID:0:7})
            if(( $SUCCESS==1 )); 
            then
              cd ~/project/backend
              npm install
              npm run migrations:revert
            fi



jobs:
  build-frontend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: [frontend-build]
      - run:
          name: Build front-end
          command: |
            cd frontend
            npm install
            npm run build
      - save_cache:
          paths: [frontend/node_modules]
          key: frontend-build 
      - slack/notify:
          event: fail
          template: basic_fail_1
      - slack/notify:
          event: pass
          template: success_tagged_deploy_1           
      

  build-backend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: [backend-build]
      - run:
          name: Back-end build
          command: |
            cd backend
            npm install
            npm run build
        
            
      - save_cache:
          paths: [backend/node_modules]
          key: backend-build
      - slack/notify:
          event: fail
          template: basic_fail_1
      - slack/notify:
          event: pass
          template: success_tagged_deploy_1
          
  test-frontend:
    docker:
      - image: circleci/node:13.8.0
      # Docker image here
    steps:
      - checkout
      - run:
          name: Test Front-end
          command: |
            cd frontend
            npm install
            npm run test
      - slack/notify:
          event: fail
          template: basic_fail_1   
                 
  test-backend:
    docker:
      - image: circleci/node:13.8.0
      # Docker image here
    steps:
      - checkout
      - run:
          name: Test Back-end
          command: |
            cd backend
            npm install
            npm run test
      - slack/notify:
          event: fail
          template: basic_fail_1   

  scan-frontend:
    docker:
      - image: circleci/node:13.8.0
      # Docker image here
    steps:
      - checkout
      - run:
          name: Scan Front-end
          command: |
            cd frontend
            npm install
            npm audit fix --audit-level=critical --force
            npm audit --audit-level=critical
      - slack/notify:
          event: fail
          template: basic_fail_1   

  scan-backend:
    docker:
      - image: circleci/node:13.8.0
      # Docker image here
    steps:
      - checkout
      - run:
          name: Scan Back-end
          command: |
            cd backend
            npm install
            npm audit fix --audit-level=critical --force

      - slack/notify:
          event: fail
          template: basic_fail_1   
 

  deploy-infrastructure:
    docker:
      - image: amazon/aws-cli
      # Docker image here
    steps:
      - checkout
      - aws-cli/setup
      - run:
          name: Ensure backend infrastructure exist
          command: |
            yum install -y tar gzip
            aws cloudformation deploy \
              --template-file .circleci/files/backend.yml \
              --stack-name "udapeople-backend-${CIRCLE_WORKFLOW_ID:0:7}" \
              --parameter-overrides ID="${CIRCLE_WORKFLOW_ID:0:7}"  \
              --tags project=udapeople

            export BACKEND_URL=$(aws cloudformation describe-stacks \
              --stack-name backend-"${CIRCLE_WORKFLOW_ID:0:7}" \
              --query "Stacks[0].Outputs[?OutputKey=='BackendURL'].OutputValue" \
              --no-paginate --output text)
            echo $BACKEND_URL
            echo "${BACKEND_URL}" >> .circleci/ansible/inventory.txt
            curl https://kvdb.io/Dvw7Sb8Hz69YirzDipb8Ld/values/backendurl -d "${BACKEND_URL}"

      - run:
          name: Ensure front-end infrastructure exist
          command: |
            aws cloudformation deploy \
              --template-file .circleci/files/frontend.yml \
              --tags project=udapeople-frontend \
              --stack-name frontend-"${CIRCLE_WORKFLOW_ID:0:7}" \
              --parameter-overrides ID="${CIRCLE_WORKFLOW_ID:0:7}"
      - run:
          name: Add back-end ip to ansible inventory
          command: |
            export BACKEND_URL=$(curl https://kvdb.io/Dvw7Sb8Hz69YirzDipb8Ld/values/backendurl)
            echo "${BACKEND_URL}" >> .circleci/ansible/inventory.txt
            cat .circleci/ansible/inventory.txt
      - run: yum -y install tar gzip
      - persist_to_workspace:
          root: .circleci/ansible
          paths:
            - inventory.txt
      # This command has a when: on_fail
      - destroy-environment:
          workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"  

  configure-infrastructure:
    docker:
      - image: python:3.9.1-alpine3.12
      # Docker image here that supports Ansible
    steps:
      # Checkout code from git
      - checkout
      # Add ssh keys with fingerprint
      - add_ssh_keys:
          fingerprints: ['32:d6:78:83:46:dc:d6:47:af:a8:45:6b:b5:d1:f8:03'] #['1d:15:4f:92:da:d5:c7:61:58:1e:58:11:38:b5:53:b4:fa:5e:08:b0'] # ["5f:7b:d4:d7:d8:88:61:0b:21:eb:b9:cc:cd:ed:53:c1"]
      # attach workspace
      - attach_workspace:
          at: /tmp/.circleci/ansible
      - run:
          name: Install dependencies
          # install the dependencies needed for your playbook
          command: |   
            apk add --update ansible 
            cat .circleci/ansible/inventory.txt
      - run:
          name: Configure server
          command: |
            echo ENVIRONMENT=production > "backend/.env"
            echo TYPEORM_CONNECTION=postgres >> "backend/.env"
            echo TYPEORM_ENTITIES=./src/modules/domain/**/*.entity.ts >> "backend/.env"
            echo TYPEORM_MIGRATIONS=./src/migrations/*.ts >> "backend/.env"
            echo TYPEORM_MIGRATIONS_DIR=./src/migrations >> "backend/.env"
            echo NODE_ENV=production >> "backend/.env"
            echo TYPEORM_HOST=$TYPEORM_HOST >> "backend/.env"
            echo TYPEORM_PORT=$TYPEORM_PORT >> "backend/.env"
            echo TYPEORM_USERNAME=$TYPEORM_USERNAME >> "backend/.env"
            echo TYPEORM_PASSWORD=$TYPEORM_PASSWORD >> "backend/.env"
            echo TYPEORM_DATABASE=$TYPEORM_DATABASE >> "backend/.env"
            ansible-playbook \
              -i /tmp/.circleci/ansible/inventory.txt \
              .circleci/ansible/configure-server.yml  

  run-migrations:
    docker:
      # Docker image here that supports NodeJS
      - image: circleci/node:13.8.0
    steps:
      # Checkout code from git
      - checkout
      - aws-cli/setup
      
      - run:
          name: Run migrations
          command: |
            echo ENVIRONMENT=production > "backend/.env"
            echo TYPEORM_CONNECTION=postgres >> "backend/.env"
            echo TYPEORM_ENTITIES=./src/modules/domain/**/*.entity.ts >> "backend/.env"
            echo TYPEORM_MIGRATIONS=./src/migrations/*.ts >> "backend/.env"
            echo TYPEORM_MIGRATIONS_DIR=./src/migrations >> "backend/.env"
            echo NODE_ENV=production >> "backend/.env"
            echo TYPEORM_HOST=$TYPEORM_HOST >> "backend/.env"
            echo TYPEORM_PORT=$TYPEORM_PORT >> "backend/.env"
            echo TYPEORM_USERNAME=$TYPEORM_USERNAME >> "backend/.env"
            echo TYPEORM_PASSWORD=$TYPEORM_PASSWORD >> "backend/.env"
            echo TYPEORM_DATABASE=$TYPEORM_DATABASE >> "backend/.env"    
           
            cd backend
            cat .env             
            sudo npm install           
            npm run build
            sudo npm run migrations > migration-log.txt
            cat migration-log.txt
        # migration_successful=$(grep -o -i "has been executed successfully" migration-log.txt | wc -l)
        # if [ $migration_succesful > 0 ]; then exit 0; else exit 1; fi;                      
                        
       
      - run:
          name: Send migration results to kvdb
          command: |

            curl -k https://kvdb.io/Dvw7Sb8Hz69YirzDipb8Ld/migration_${CIRCLE_WORKFLOW_ID:0:7}  -d '1' 
            
      - persist_to_workspace:
          root: ~/project
          paths:
            - backend

      # - destroy-environment:
      #     workflow_id: "${CIRCLE_WORKFLOW_ID}"
      # # - revert-migrations
      # # - destroy-environment


     # Here's where you will add some code to rollback on failure
     # Nothing really.

  deploy-frontend:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - restore_cache:
          keys: [frontend-build]
      - run:
          name: Install dependencies
          command: |
            yum install -y curl tar sudo
            curl -sL https://rpm.nodesource.com/setup_13.x | sudo bash -
            yum install -y nodejs
            node --version
      - run:
          name: Get backend url
          command: |
            export API_URL=$(curl https://kvdb.io/Dvw7Sb8Hz69YirzDipb8Ld/values/backendurl)
            export API_URL="http://${API_URL}:3030"
            echo "${API_URL}" > .circleci/api_url.txt
      - run:
          name: Deploy frontend objects
          command: |
            export API_URL=$(cat .circleci/api_url.txt)
            echo "${API_URL}" > frontend/.env
            cd frontend
            npm i
            npm run build
            aws s3 cp dist s3://udapeople-"${CIRCLE_WORKFLOW_ID:0:7}" --recursive
      - destroy-environment:
          workflow_id: ${CIRCLE_WORKFLOW_ID:0:7}



  deploy-backend:
    docker:
      - image: python:3.9.1-alpine3.12
    steps:
      - checkout
      - add_ssh_keys:        
          fingerprints: ['32:d6:78:83:46:dc:d6:47:af:a8:45:6b:b5:d1:f8:03'] #['1d:15:4f:92:da:d5:c7:61:58:1e:58:11:38:b5:53:b4:fa:5e:08:b0'] # ["5f:7b:d4:d7:d8:88:61:0b:21:eb:b9:cc:cd:ed:53:c1"]
      - restore_cache:
          keys: [backend-build]
      - attach_workspace:
          at: /tmp/artifacts
      - run:
          name: Install dependencies
          command: |
            apk update
            apk add --update ansible aws-cli openssh-client tar
      - run:
          name: compress backend
          command: |
            tar -C /tmp/artifacts/backend -czvf artifact.tar.gz .
      - run:
          name: Deploy backend
          command: |
            cd .circleci/ansible
            export ANSIBLE_HOST_KEY_CHECKING=False
            ansible-playbook -i /tmp/artifacts/inventory.txt deploy-backend.yml
      - destroy-environment:
          workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"


  smoke-test:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - run:
          name: Install dependencies
          command: |
            sudo apt update
            sudo apt install -y awscli
            sudo apt install -y python3 ansible
      - run:
          name: Get backend url
          command: |
            curl -k https://kvdb.io/Dvw7Sb8Hz69YirzDipb8Ld/values/backendurl > backend-url.txt
      - run:
          name: Backend smoke test.
          command: |
            url=$(cat backend-url.txt)
            url="http://${url}:3030/api/status"
            curl $url
      - run:
          name: Frontend smoke test.
          command: |
            URL="http://udapeople-${CIRCLE_WORKFLOW_ID:0:7}.s3-website-us-east-1.amazonaws.com"
            echo ${URL}
            if curl -s ${URL} | grep "Welcome"
            then
                # Change this to 0 after the job fails
              return 1
            else
              return 1
            fi
             
      - destroy-environment:
          workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"


  cloudfront-update:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Install dependencies
          command: |
            yum install -y curl
      - run:
          name: Update cloudfront distribution
          command: |
            export OldWorkflowID=$(aws cloudformation \
              list-exports --query "Exports[?Name==\`WorkflowID\`].Value" \
              --no-paginate --output text)
            export STACKS=($(aws cloudformation list-stacks --query "StackSummaries[*].StackName" \
              --stack-status-filter CREATE_COMPLETE --no-paginate --output text))
            echo "${OldWorkflowID}"
            echo "${STACKS[@]}"
            # save oldworkflowid for the cleanup phase
            curl https://kvdb.io/Dvw7Sb8Hz69YirzDipb8Ld/values/oldworkflowid -d "${OldWorkflowID}"
            # promote
            aws cloudformation update-stack \
              --use-previous-template \
              --stack-name cloudfront-${OldWorkflowID} \
              --parameters ParameterKey=WorkflowID,ParameterValue=$CIRCLE_WORKFLOW_ID,UsePreviousValue=false
      # Here's where you will add some code to rollback on failure
      - destroy-environment:
          workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"



  cleanup:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Remove old stacks and files
          command: |
            export OldWorkflowID=$(curl https://kvdb.io/Dvw7Sb8Hz69YirzDipb8Ld/values/oldworkflowid)
            if [[ "${STACKS[@]}" =~ "${OldWorkflowID}" ]]
            then
              aws s3 rm s3://udapeople-"${OldWorkflowID}" --recursive
              aws cloudformation delete-stack --stack-name frontend-"${OldWorkflowID}"
              aws cloudformation delete-stack --stack-name backend-"${OldWorkflowID}"
              aws cloudformation delete-stack --stack-name cloudfront-"${OldWorkflowID}"
            fi
              
            
 
workflows: 
  default:
    jobs:
      - build-frontend
      - build-backend
      - test-frontend:
          requires: [build-frontend]
      - test-backend:
          requires: [build-backend]
      - scan-frontend:
          requires: [build-frontend]
      - scan-backend:
          requires: [build-backend]
      - deploy-infrastructure:
          requires: [test-frontend,test-backend,scan-frontend,scan-backend]
          filters:
            branches:
              only: [master]
      - configure-infrastructure:
          requires: [deploy-infrastructure]
      - run-migrations:
          requires: [configure-infrastructure]
      - deploy-frontend:
          requires: [run-migrations]
      - deploy-backend:
          requires: [run-migrations]
      - smoke-test:
          requires: [deploy-backend, deploy-frontend]
      - cloudfront-update:
          requires: [smoke-test]
      - cleanup:
          requires: [cloudfront-update]


