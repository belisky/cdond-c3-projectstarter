version: 2.1
orbs:
  node: circleci/node@5.0.2
  slack: circleci/slack@4.10.1
  aws-cli: circleci/aws-cli@1.3.0

# Define a job to be invoked later in a workflow.
# See: https://circleci.com/docs/2.0/configuration-reference/#jobs
commands:
  destroy-environment:
    description: Destroy back-end and front-end cloudformation stacks given a workflow ID.
    parameters:
      workflow_id:
        type: string
    steps:
      - run:          
          name: Destroy environments
          when: on_fail
          command: |          
            aws cloudformation delete-stack --stack-name "udapeople-backend-${CIRCLE_WORKFLOW_ID:0:7}"
            aws cloudformation delete-stack --stack-name "frontend-${CIRCLE_WORKFLOW_ID:0:7}"

  revert-migrations:
    description: Revert the last migration if successfully run in the current workflow.
   
    steps:
      # Trigger rollback jobs if the smoke tests or any following jobs fail.
      # Revert the last migration (IF a new migration was applied) on the database to that it goes back to the way it was before. You can use that value you saved in MemStash.io to know if you should revert any migrations.
      - run:
          name: Revert migrations
          when: on_fail
          command: |
            # Curl command here to see if there was a successful migration associated with the workflow id, store result in SUCCESS variable
            export SUCCESS=$(curl --insecure https://kvdb.io/Dvw7Sb8Hz69YirzDipb8Ld/migration_$\{CIRCLE_WORKFLOW_ID:0:7\})
            if(( $SUCCESS==1 )); 
            then
              cd ~/project/backend
              npm install
              npm run migrations:revert
            fi



jobs:
  build-frontend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: [frontend-build]
      - run:
          name: Build front-end
          command: |
            cd frontend
            npm install
            npm run build
      - save_cache:
          paths: [frontend/node_modules]
          key: frontend-build 
      - slack/notify:
          event: fail
          template: basic_fail_1
      - slack/notify:
          event: pass
          template: success_tagged_deploy_1           
      

  build-backend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: [backend-build]
      - run:
          name: Back-end build
          command: |
            cd backend             
            npm install
            npm run build        
            
      - save_cache:
          paths: [backend/node_modules]
          key: backend-build
      - slack/notify:
          event: fail
          template: basic_fail_1
      - slack/notify:
          event: pass
          template: success_tagged_deploy_1
          
  test-frontend:
    docker:
      - image: circleci/node:13.8.0
      # Docker image here
    steps:
      - checkout
      - restore_cache:
          keys: [frontend-build]
      - run:
          name: Test Front-end
          command: |
            cd frontend
            npm install
            npm run test
      - slack/notify:
          event: fail
          template: basic_fail_1   
                 
  test-backend:
    docker:
      - image: circleci/node:13.8.0
      # Docker image here
    steps:
      - checkout
      - restore_cache:
          keys: [backend-build]
      - run:
          name: Test Back-end
          command: |
            cd backend
            npm install
            npm run test
      - slack/notify:
          event: fail
          template: basic_fail_1   

  scan-frontend:
    docker:
      - image: circleci/node:13.8.0
      # Docker image here
    steps:
      - checkout
      - restore_cache:
          keys: [frontend-build]
      - run:
          name: Scan Front-end
          command: |
            cd frontend
            npm install
            npm audit fix --audit-level=critical --force
       
      - slack/notify:
          event: fail
          template: basic_fail_1   

  scan-backend:
    docker:
      - image: circleci/node:13.8.0
      # Docker image here
    steps:
      - checkout
      - restore_cache:
          keys: [backend-build]
      - run:
          name: Scan Back-end
          command: |
            cd backend
            npm install
            npm audit fix --audit-level=critical --force

      - slack/notify:
          event: fail
          template: basic_fail_1   
 

  deploy-infrastructure:
    docker:
      - image: cimg/base:2020.01
      # Docker image here
    steps:
      - checkout
      - aws-cli/setup
      - run:
          name: Ensure frontend infrastructure exist
          command: |
            aws cloudformation deploy \
              --template-file .circleci/files/frontend.yml \
              --stack-name "frontend-${CIRCLE_WORKFLOW_ID:0:7}" \
              --parameter-overrides ID="${CIRCLE_WORKFLOW_ID:0:7}" \
              --tags project=udapeople 
          
      - run:
          name: Ensure backend infrastructure exist
          command: |             
            aws cloudformation deploy \
              --template-file .circleci/files/backend.yml \
              --stack-name "backend-${CIRCLE_WORKFLOW_ID:0:7}" \
              --parameter-overrides ID="${CIRCLE_WORKFLOW_ID:0:7}" \
              --tags project=udapeople 
   
 
      - run:
          name: Add back-end ip to ansible inventory
          command: |
            aws ec2 describe-instances \
              --query 'Reservations[*].Instances[*].PublicIpAddress' \
              --filters "Name=tag:project,Values=udapeople" \
              --output text >> .circleci/ansible/inventory.txt
            export BACKEND_IP=$(sed -n 2p .circleci/ansible/inventory.txt)            
            curl --insecure https://kvdb.io/Dvw7Sb8Hz69YirzDipb8Ld/values/backendurl -d $BACKEND_IP
             


            export BACKEND_URL=$(aws cloudformation describe-stacks \
              --stack-name backend-"${CIRCLE_WORKFLOW_ID:0:7}" \
              --query "Stacks[0].Outputs[?OutputKey=='BackendURL'].OutputValue" \
              --no-paginate --output text)

            echo $BACKEND_URL
            curl --insecure https://kvdb.io/Dvw7Sb8Hz69YirzDipb8Ld/values/backendurls -d $BACKEND_URL
    
      - persist_to_workspace:
          root: .circleci/ansible
          paths:
            - inventory.txt 

      - destroy-environment:
          workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"
     
  

  configure-infrastructure:
    docker:
      - image: python:3.9.1-alpine3.12
      # Docker image here that supports Ansible
    steps:
      # Checkout code from git
      - checkout
      # Add ssh keys with fingerprint
      - add_ssh_keys:
          fingerprints: ['32:d6:78:83:46:dc:d6:47:af:a8:45:6b:b5:d1:f8:03'] #['1d:15:4f:92:da:d5:c7:61:58:1e:58:11:38:b5:53:b4:fa:5e:08:b0'] # ["5f:7b:d4:d7:d8:88:61:0b:21:eb:b9:cc:cd:ed:53:c1"]
      # attach workspace
      - attach_workspace:
          at: /tmp/.circleci/ansible
      - run:
          name: Install dependencies
          # install the dependencies needed for your playbook
          command: |   
            apk add --update ansible aws-cli
            cat .circleci/ansible/inventory.txt
     
      - run:
          name: Configure server
          command: |
            echo ENVIRONMENT=production > "backend/.env"
            echo TYPEORM_CONNECTION=postgres >> "backend/.env"
            echo TYPEORM_ENTITIES=./src/modules/domain/**/*.entity.ts >> "backend/.env"
            echo TYPEORM_MIGRATIONS=./src/migrations/*.ts >> "backend/.env"
            echo TYPEORM_MIGRATIONS_DIR=./src/migrations >> "backend/.env"
            echo NODE_ENV=production >> "backend/.env"
            echo TYPEORM_HOST=$TYPEORM_HOST >> "backend/.env"
            echo TYPEORM_PORT=$TYPEORM_PORT >> "backend/.env"
            echo TYPEORM_USERNAME=$TYPEORM_USERNAME >> "backend/.env"
            echo TYPEORM_PASSWORD=$TYPEORM_PASSWORD >> "backend/.env"
            echo TYPEORM_DATABASE=$TYPEORM_DATABASE >> "backend/.env"
            ansible-playbook \
              -i /tmp/.circleci/ansible/inventory.txt \
              .circleci/ansible/configure-server.yml  

      - destroy-environment:
          workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"
     

  run-migrations:
    docker:
      # Docker image here that supports NodeJS
      - image: circleci/node:13.8.0
    steps:
      # Checkout code from git
      - checkout
      - aws-cli/setup
      - restore_cache:
          keys: [backend-build]
      
      - run:
          name: prepare environment for backend build
          command: |
            echo ENVIRONMENT=production > "backend/.env"
            echo TYPEORM_CONNECTION=postgres >> "backend/.env"
            echo TYPEORM_ENTITIES=./src/modules/domain/**/*.entity.ts >> "backend/.env"
            echo TYPEORM_MIGRATIONS=./src/migrations/*.ts >> "backend/.env"
            echo TYPEORM_MIGRATIONS_DIR=./src/migrations >> "backend/.env"
            echo NODE_ENV=production >> "backend/.env"
            echo TYPEORM_HOST=$TYPEORM_HOST >> "backend/.env"
            echo TYPEORM_PORT=$TYPEORM_PORT >> "backend/.env"
            echo TYPEORM_USERNAME=$TYPEORM_USERNAME >> "backend/.env"
            echo TYPEORM_PASSWORD=$TYPEORM_PASSWORD >> "backend/.env"
            echo TYPEORM_DATABASE=$TYPEORM_DATABASE >> "backend/.env"  

            sudo apt update
            sudo apt install -y awscli

      - run:
          name: Install dependencies
          command: |           
           
            cd backend
            cat .env             
            sudo npm install           
            npm run build
            sudo npm run migrations > migration-log.txt
            cat migration-log.txt

            if cat migration-log.txt | grep "has been executed successfully"; then
              exit 0
            fi
        # migration_successful=$(grep -o -i "has been executed successfully" migration-log.txt | wc -l)
        # if [ $migration_succesful > 0 ]; then exit 0; else exit 1; fi;                      
                        
       
      - run:
          name: Send migration results to kvdb
          command: |

            curl --insecure https://kvdb.io/Dvw7Sb8Hz69YirzDipb8Ld/migration_$\{CIRCLE_WORKFLOW_ID:0:7\}  -d '1' 

      - persist_to_workspace:
          root: ~/project
          paths:
            - backend  

      - destroy-environment:
          workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"
      - revert-migrations
      # # - destroy-environment


     # Here's where you will add some code to rollback on failure
     # Nothing really.

  deploy-frontend:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - restore_cache:
          keys: [frontend-build]        
          
      - run:
          name: Install dependencies
          command: |
            yum install -y curl tar sudo
            curl -sL https://rpm.nodesource.com/setup_13.x | sudo bash -
            yum install -y nodejs
            node --version
      - run:
          name: Get backend url
          command: |
            export BACKEND_IP=$(sed -n 2p .circleci/ansible/inventory.txt)
            echo $BACKEND_IP
             
            export API_URL="http://${BACKEND_IP}:3030"
            echo ENVIRONMENT=production > frontend/.env
            echo NODE_ENV=production >> frontend/.env
            echo API_URL=$API_URL >> frontend/.env
            echo $API_URL
            
      - run:
          name: Build frontend
          command: |
            cd frontend
            npm i      
             
            npm run build
  
      - run:
          name: Deploy frontend objects
          command: |
            aws s3 cp frontend/dist "s3://udapeople-${CIRCLE_WORKFLOW_ID:0:7}" --recursive
  


  deploy-backend:
    docker:
      - image: python:3.9.1-alpine3.12
    steps:
      - checkout
      - add_ssh_keys:        
          fingerprints: ['32:d6:78:83:46:dc:d6:47:af:a8:45:6b:b5:d1:f8:03'] #['1d:15:4f:92:da:d5:c7:61:58:1e:58:11:38:b5:53:b4:fa:5e:08:b0'] # ["5f:7b:d4:d7:d8:88:61:0b:21:eb:b9:cc:cd:ed:53:c1"]
      - restore_cache:
          keys: [backend-build]
      - attach_workspace:
          at: /tmp/artifacts
      - run:
          name: Install dependencies
          command: |
            apk update
            apk add --update ansible aws-cli openssh-client tar
      - run:
          name: compress backend
          command: |
            tar -C /tmp/artifacts/backend -czvf artifact.tar.gz .
      - run:
          name: Deploy backend
          command: |
            cd .circleci/ansible
            export ANSIBLE_HOST_KEY_CHECKING=False
            ansible-playbook -i /tmp/artifacts/inventory.txt deploy-backend.yml
      - destroy-environment:
          workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"
      - revert-migrations



  smoke-test:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - run:
          name: Install dependencies
          command: |
            sudo apt update
            sudo apt install -y awscli
            sudo apt install -y python3 ansible
      - run:
          name: Get backend url
          command: |          
            curl --insecure https://kvdb.io/Dvw7Sb8Hz69YirzDipb8Ld/values/backendurls > backend-url.txt
            curl --insecure https://kvdb.io/Dvw7Sb8Hz69YirzDipb8Ld/values/backendurl > backend-url1.txt
      - run:
          name: Backend smoke test.
          command: |
            url=$(cat backend-url.txt)  
            url1=$(cat backend-url1.txt)  
            echo $url  
            echo $url1   
            url="http://${url}:3030/api/status" 
            url1="http://${url1}:3030/api/status" 
            echo $url            
            echo $url1            
            cat /.circleci/ansible/inventory.txt
            BACKEND_IP1=$(sed -n 2p /.circleci/ansible/inventory.txt)
            cat $BACKEND_IP
            echo $BACKEND_IP1
            cat $BACKEND_IP1           
            curl "http://${BACKEND_IP}:3030"
            curl "http://${BACKEND_IP}:3030/api/status"
            curl "http://${BACKEND_IP1}:3030"
            curl "http://${BACKEND_IP1}:3030/api/status"
            curl $url1
            curl $url

        
      - run:
          name: Frontend smoke test.
          command: |
            URL="http://udapeople-${CIRCLE_WORKFLOW_ID:0:7}.s3-website-us-east-1.amazonaws.com"
            echo ${URL}
            curl -s ${URL}              
      - destroy-environment:
          workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"
      - revert-migrations           


  cloudfront-update:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Install dependencies
          command: |
            yum install -y curl
      - run:
          name: Update cloudfront distribution
          command: |
            export OldWorkflowID=$(aws cloudformation \
              list-exports --query "Exports[?Name==\`WorkflowID\`].Value" \
              --no-paginate --output text)
            export STACKS=($(aws cloudformation list-stacks --query "StackSummaries[*].StackName" \
              --stack-status-filter CREATE_COMPLETE --no-paginate --output text))
            echo "${OldWorkflowID}"
            echo "${STACKS[@]}"
            # save oldworkflowid for the cleanup phase
            echo $OldWorkflowID
            curl --insecure https://kvdb.io/Dvw7Sb8Hz69YirzDipb8Ld/values/oldworkflowid -d $OldWorkflowID
            # promote
            aws cloudformation update-stack \
              --use-previous-template \
              --stack-name cloudfront-${OldWorkflowID} \
              --parameters ParameterKey=WorkflowID,ParameterValue=$CIRCLE_WORKFLOW_ID,UsePreviousValue=false
      # Here's where you will add some code to rollback on failure
      - destroy-environment:
          workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"
      - revert-migrations
           



  cleanup:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Remove old stacks and files
          command: |
            export OldWorkflowID=$(curl --insecure https://kvdb.io/Dvw7Sb8Hz69YirzDipb8Ld/values/oldworkflowid)
            if [[ "${STACKS[@]}" =~ "${OldWorkflowID}" ]]
            then
              aws s3 rm s3://udapeople-"${OldWorkflowID}" --recursive
              aws cloudformation delete-stack --stack-name frontend-"${OldWorkflowID}"
              aws cloudformation delete-stack --stack-name backend-"${OldWorkflowID}"
              aws cloudformation delete-stack --stack-name cloudfront-"${OldWorkflowID}"
            fi
              
            
 
workflows: 
  default:
    jobs:
      - build-frontend
      - build-backend
      - test-frontend:
          requires: [build-frontend]
      - test-backend:
          requires: [build-backend]
      - scan-frontend:
          requires: [build-frontend]
      - scan-backend:
          requires: [build-backend]
      - deploy-infrastructure:
          requires: [test-frontend,test-backend,scan-frontend,scan-backend]
          filters:
            branches:
              only: [master]
      - configure-infrastructure:
          requires: [deploy-infrastructure]
      - run-migrations:
          requires: [configure-infrastructure]
      - deploy-frontend:
          requires: [run-migrations]
      - deploy-backend:
          requires: [run-migrations]
      - smoke-test:
          requires: [deploy-backend, deploy-frontend]
      - cloudfront-update:
          requires: [smoke-test]
      - cleanup:
          requires: [cloudfront-update]


